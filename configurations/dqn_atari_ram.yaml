# env setting
env_id: ALE/Pong-ram-v5
render: false
env_option:
    frame_skip: 4
    frame_stack: 4
    repeat_action_probability: 0.
wrapper_option:
  TransformReward: {f: "lambda reward: np.sign(float(reward))"}

# dqn setting
network_type: Default
network_config:
  Q_network:
    hidden_units: [64, 64]
eps_initial: 1.0
eps_final: 0.01
decay_fraction: 0.1
gamma: 0.99
batch_size: 32
buffer_size: 1000000
learning_rate: 0.0001
optimizer: Adam
optimizer_kwargs: {}
target_copy_freq: 1000
device: cpu

# trainer setting
seed: 1
training_start: 80000
training_freq: 1
training_num: 1
max_step: 10000000
do_eval: true
eval_every: 10000
eval_ep: 1

# log setting
log_tensorboard: true
log_wandb: true
record_video: true
save_model: false
save_freq: 100000

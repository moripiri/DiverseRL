env_id: ALE/Pong-v5
render: false
env_option:
    frame_skip: 4
    frame_stack: 4
    repeat_action_probability: 0.
    image_size: 84
    noop_max: 30
    terminal_on_life_loss: True
    grayscale_obs: True
wrapper_option:
  TransformReward: {f: "lambda reward: np.sign(float(reward))"}
num_envs: 8

network_type: Default
network_config:
  Actor:
    hidden_units: []
    kernel_initializer: orthogonal_
    kernel_initializer_kwargs: {"gain": 0.01}
    bias_initializer: constant_
    bias_initializer_kwargs: {"val": 0.0}
  Critic:
    hidden_units: []
    kernel_initializer: orthogonal_
    kernel_initializer_kwargs: {"gain": 1}
    bias_initializer: constant_
    bias_initializer_kwargs: {"val": 0.0}
  Encoder:
    feature_dim: 512
  Buffer:
    optimize_memory_usage: True
mode: clip
clip_coef: 0.1
target_dist: 0.01
beta: 3.0
gamma: 0.99
lambda_gae: 0.95
vf_coef: 0.5
entropy_coef: 0.01
horizon: 128
minibatch_size: 32
num_epochs: 4
learning_rate: 0.00025
optimizer: Adam
optimizer_kwargs: {"eps": 1e-05}
anneal_lr: true
max_grad_norm: 0.5
device: cpu
seed: 1

max_step: 10000000
do_eval: false
eval_every: 10000
eval_ep: 1
log_tensorboard: false
log_wandb: false
record_video: false
save_model: false
save_freq: 100000

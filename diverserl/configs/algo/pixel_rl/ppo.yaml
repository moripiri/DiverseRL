_target_: diverserl.algos.pixel_rl.PPO
network_type: Default
network_config:
  Actor:
    hidden_units: []
    mid_activation: "Tanh"
    kernel_initializer: "orthogonal_"
    kernel_initializer_kwargs: {"gain": "np.sqrt(2)"}
    bias_initializer: "constant_"
    bias_initializer_kwargs: {"val": 0.0}
  Critic:
    hidden_units: []
    mid_activation: "Tanh"
    kernel_initializer: "orthogonal_"
    kernel_initializer_kwargs: {"gain": "np.sqrt(2)"}
    bias_initializer: "constant_"
    bias_initializer_kwargs: {"val": 0.0}
  Encoder:
    feature_dim: 512
horizon: 128
minibatch_size: 32
num_epochs: 4
gamma: 0.99
lambda_gae: 0.95
mode: clip
target_dist: 0.01
beta: 3.0
clip_coef: 0.2
vf_coef: 0.5
entropy_coef: 0.0
max_grad_norm: 0.5
learning_rate: 0.00025
optimizer: Adam
optimizer_kwargs: {"eps": 0.00001}
anneal_lr: true
device: cpu
